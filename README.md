# BRI-FLOW

Editor visual (frontend) para dise√±ar flujos conversacionales/procesos mediante nodos conectables. El resultado es un JSON estructurado que describe el flujo.

Este repositorio contiene el **editor** y utilidades de **simulaci√≥n**. El backend/runtime que ejecuta el JSON en producci√≥n no est√° incluido aqu√≠.

## Demo

- Online: https://elbrinner.com/flow/

## Documentaci√≥n

- √çndice: [docs/README.md](docs/README.md)
- Nodos: [docs/nodos.md](docs/nodos.md) (compat: [docs/nodo.md](docs/nodo.md))
- Expresiones: [docs/expresiones.md](docs/expresiones.md)
- Desarrollo local: [docs/desarrollo.md](docs/desarrollo.md)
- Pruebas: [docs/pruebas.md](docs/pruebas.md)

## Ejecutar en local

Opci√≥n recomendada (servidor est√°tico):

1. `python3 -m http.server 8081`
2. Abrir `http://localhost:8081`

Opci√≥n r√°pida:

- Abrir `index.html` en el navegador.

## Desarrollo

1. Instalar dependencias (solo necesarias para tests): `npm install`
2. Ejecutar pruebas:
   - E2E (Playwright): `npm run test:e2e`
  - Runners HTML del simulador: `tests/test-runner.html` y `tests/test-runner-nodes.html`

Nota: el script `npm run test:form` existe como prueba legacy de Node+JSDOM, pero actualmente referencia un archivo no presente (`js/nodes/processForm.js`).

Notas para E2E:

- Primera vez: `npx playwright install`
- La config levanta un server local en `http://localhost:8081` (ver `playwright.config.js`).

## Estructura

- `index.html`: UI principal del editor
- `components/`: paneles/modales HTML
- `css/`: estilos
- `js/`: l√≥gica del editor, renderers, serializer y simulador
- `tests/`: unit/smoke y E2E

## Licencia

MIT. Ver [LICENSE.md](LICENSE.md).

**Funciones l√≥gicas**: `coalesce()`, `iif()`, `isEmpty()`, `isNotEmpty()`

**Funciones matem√°ticas**: `sum()`, `avg()`, `min()`, `max()`, `round()`

üìñ Documentaci√≥n completa de funciones y ejemplos: [docs/nodo.md#expresiones-y-funciones-disponibles](docs/nodo.md#expresiones-y-funciones-disponibles)

---

**Nota importante**: Todos los flujos deben terminar expl√≠citamente con un nodo `end`. Aunque algunos recorridos puedan parecer "finales" (p. ej., sin `next`), normaliza tu dise√±o para que cada camino concluya en `end`; esto facilita validaciones, simulaci√≥n y exportaciones.

## C√≥mo ejecutar en local

Requisitos m√≠nimos:
- Navegador moderno (Chrome, Edge, Firefox, Safari actualizados).
- No requiere build ni dependencias: es una app est√°tica (HTML/CSS/JS).

Opciones de ejecuci√≥n:

- Opci√≥n A ‚Äî Abrir el archivo directamente
  - Abre `index.html` con doble clic o desde tu navegador.
  - √ötil para una prueba r√°pida del editor y el simulador.
  - Nota: los nodos `rest_call` y cualquier llamada HTTP NO funcionar√°n al abrir por `file://` debido a pol√≠ticas del navegador (origen de archivo/CORS). Para probar llamadas HTTP usa la Opci√≥n B (servidor).

- Opci√≥n B ‚Äî Servir como sitio est√°tico (recomendado)
  - Usa cualquier servidor HTTP est√°tico para la carpeta del proyecto (por ejemplo, una extensi√≥n tipo ‚ÄúLive Server‚Äù en VS Code).
  - Ventajas: comportamiento m√°s realista, evita restricciones del navegador al abrir archivos locales.
  - En VS Code: instala la extensi√≥n ‚ÄúLive Server‚Äù, abre este proyecto y pulsa ‚ÄúGo Live‚Äù para abrirlo en `http://localhost:<puerto>`.
  - Arranque r√°pido opcional (Windows PowerShell):
    - Si tienes Python:
      
      ```powershell
      # en la ra√≠z del proyecto
      py -m http.server 5500
      # luego abre http://localhost:5500
      ```

    - Si tienes Node.js:

      ```powershell
      # en la ra√≠z del proyecto
      npx http-server -p 5500
      # luego abre http://localhost:5500
      ```

Flujo b√°sico de uso
1) Abre la app en el navegador (por archivo directo o `http://localhost:<puerto>` si usas un servidor).
2) Crea un flujo con `start` ‚Üí a√±ade nodos ‚Üí conecta destinos.
3) Usa el simulador para validar recorridos. Recuerda: el simulador es orientativo; la ejecuci√≥n real depende del backend propietario.

Notas √∫tiles
- Persistencia: el proyecto/estado del editor se guarda en el almacenamiento local del navegador (localStorage). Si quieres ‚Äúresetear‚Äù el estado, limpia el almacenamiento del sitio desde las herramientas de desarrollador del navegador.
- Llamadas externas: nodos como `rest_call` pueden necesitar un backend accesible y con CORS habilitado para pruebas reales. En ausencia de eso, util√≠zalos solo como referencia estructural durante el dise√±o.

## Pruebas del simulador (paridad y avanzadas)

Para ejecutar las pruebas del simulador (paridad de funciones y casos avanzados) usa la p√°gina dedicada del runner, no el `index.html` principal:

- Abre: `tests/test-runner.html`
- All√≠ encontrar√°s botones para:
  - ‚ÄúTests listas‚Äù (addItem, removeItem, removeAt)
  - ‚ÄúTests expresiones‚Äù (todas las funciones documentadas y composiciones)
  - ‚ÄúTests avanzados‚Äù (nesting de join/split/addItem, coalesce con join vac√≠o, √≠ndices fuera de rango, igualdad laxa, etc.)

Los resultados se muestran en el panel de la p√°gina y en la consola del navegador.

## Configuraci√≥n local del simulador (REST y Agente)

Para validar flujos que hacen llamadas reales a servicios (REST o Agente) o para trabajar en modo mock sin editar nodos uno por uno, puedes colocar un archivo opcional `docs/sim.local.json`. Al cargar la app, el simulador intentar√° leerlo autom√°ticamente.

Ejemplo de `docs/sim.local.json`:

```json
{
  "http_mock_global": false,
  "rest": {
    "base_url": "http://localhost:7071", 
    "default_headers": {
      "X-Env": "local",
      "Authorization": "Bearer <tu_token>"
    }
  },
  "agent_api_base": "http://localhost:5000", 
  "agent": {
    "api_base": "http://localhost:5000",
    "mock_mode": "off", 
    "mock": {
      "text": "Hola, soy un agente simulado.",
      "citations": [],
      "usage": { "prompt_tokens": 1, "completion_tokens": 1, "total_tokens": 2 },
      "threadId": "mock-thread-1"
    }
  }
}
```

Notas:
- `rest.base_url` y `rest.default_headers` se aplican a los `rest_call` cuando la URL del nodo es relativa.
- `http_mock_global` activa/desactiva el modo mock HTTP global del simulador (los nodos `rest_call` tambi√©n pueden definir mock propio por nodo).
- Para el modo ‚Äúbackend legado‚Äù de agente (si lo usas), el base se toma de `agent_api_base` (nivel ra√≠z) o `agent.api_base`.
- Para `agent_call`, adem√°s del mock por nodo (`props.mock_mode`, `props.mock`), ahora puedes controlar un mock global de agente v√≠a `agent.mock_mode` con valores:
  - `off`: nunca mock (por defecto).
  - `fallback`: usa mock s√≥lo si la llamada real falla.
  - `always`: siempre responde con el mock.

## Agentes sin backend (directo a Azure OpenAI) üîå

El simulador puede llamar directamente a Azure OpenAI, sin backend. Usa el nodo `agent_call` con un `model` como:

```json
{
  "provider": "azure-openai",
  "deployment": "gpt-4o-mini",
  "temperature": 0.2,
  "max_tokens": 800
}
```

Para no exponer secretos en el JSON del flujo, define credenciales ef√≠meras mediante nodos de utilidad:

- `credential_profile` (sim-only): guarda un perfil de credenciales en memoria del simulador.
  - Estructura t√≠pica de `credentials`:
    ```json
    {
      "aoai_endpoint": "https://<tu-recurso>.openai.azure.com",
      "aoai_api_key": "<API_KEY>",
      "aoai_api_version": "2025-01-01-preview",
      "aoai_chat_deployment": "gpt-4o-mini"
    }
    ```
  - El nodo no se persiste en el JSON exportado (tiene `__sim_only: true`).
- `use_profile`: activa el perfil por nombre (p. ej., `default`, `sim`, etc.).

Flujo m√≠nimo (sin backend):
1) `credential_profile` (profile: "default") ‚Üí 2) `use_profile` (profile: "default") ‚Üí 3) `agent_call` (model.provider = "azure-openai").

Streaming: marca la casilla ‚ÄúStreaming (SSE)‚Äù en `agent_call` para recibir chunks. Si hay CORS o red bloqueada, usa `mock_mode: "fallback"` o `"always"` (a nivel de nodo o en `sim.local.json`).

## Demos incluidas para validar

En `docs/` encontrar√°s flujos de ejemplo listos para cargar desde el simulador:

**Flujos b√°sicos**:
- **`demo_multi_button.json`**: Opciones din√°micas con `multi_button` (min/max, `save_as`) y uso de la selecci√≥n para filtrar una lista.
- **`demo_form.json`**: Formulario con guardado de variables y demostraci√≥n del nodo `extra` (ephemeral) encadenado a `response` y `debug`.

**Flujos de agentes** ‚ö†Ô∏è Requieren credenciales:
- **`demo_agent_azure_direct.json`**: Flujo m√≠nimo para llamar a Azure OpenAI directamente desde el simulador usando `credential_profile` + `use_profile` + `agent_call` (stream/no-stream).
- **`demo_agent_rag.json`**: Flujo completo de RAG (Retrieval-Augmented Generation) que demuestra b√∫squeda en Azure AI Search + generaci√≥n contextualizada con Azure OpenAI. Incluye ejemplos de buenas pr√°cticas.

**C√≥mo usar las demos**:
1. Abre el simulador (`index.html`)
2. Haz clic en **"Importar Flujo"**
3. Selecciona el archivo `.json` de la demo
4. Para demos de agentes: configura credenciales primero (ver secci√≥n "Perfiles del simulador")
5. Haz clic en **"‚ñ∂ Simular"** para ejecutar

Importa estos archivos desde la UI del simulador para validar r√°pidamente el comportamiento end-to-end.

## Perfiles del simulador (credenciales) üß©

Para gestionar credenciales de forma segura durante la simulaci√≥n sin exponerlas en los flujos exportados, el simulador incorpora un sistema de perfiles:

- Bot√≥n ‚ÄúPerfiles‚Äù en la cabecera del simulador: abre un di√°logo para crear/editar/eliminar perfiles, activar uno como ‚Äúactual‚Äù, hacer ping a Azure OpenAI e importar/exportar perfiles (JSON) en local.
- Chip de estado: muestra el perfil activo y su estado (p. ej., AOAI OK/ERROR) cuando hay datos suficientes para probar conectividad.
- Nodo `credential_profile` (sim-only): ahora incluye opciones ‚ÄúPersistir en localStorage‚Äù y ‚ÄúActivar perfil tras guardar‚Äù.
  - Si marcas ‚ÄúPersistir‚Äù, las credenciales se guardan en este navegador (localStorage) y quedar√°n disponibles en sesiones futuras. Si no, s√≥lo se mantienen en memoria mientras la p√°gina est√© abierta.
  - Este nodo jam√°s se exporta con el flujo; el serializer lo elimina y re-encadena el grafo autom√°ticamente, protegiendo tus secretos.
- Nodo `use_profile`: activa un perfil por nombre (√∫til para encadenar a `agent_call`).

Sugerencia de uso
1) Crea un perfil con tus credenciales reales (bot√≥n ‚ÄúPerfiles‚Äù) y act√≠valo.
2) O bien usa un nodo `credential_profile` al inicio del flujo con ‚ÄúPersistir‚Äù y ‚ÄúActivar‚Äù marcados para preparar el entorno de pruebas autom√°ticamente.
3) Ejecuta `agent_call` con provider `azure-openai`. Si hay problemas de CORS o red, habilita `mock_mode: "fallback"` o `"always"` en el nodo o en `docs/sim.local.json`.

### Campos admitidos en un perfil

Un perfil del simulador puede incluir distintos bloques, inspirados en `appsettings.*.json` del backend:

```
{
  "name": "default",
  "aoai_endpoint": "https://<recurso>.openai.azure.com",
  "aoai_api_key": "<API_KEY>",
  "aoai_api_version": "2025-01-01-preview",
  "aoai_chat_deployment": "gpt-4.1-mini",
  "aoai_embeddings_deployment": "text-embedding-3-large",          // opcional
  "aoai_embeddings_api_version": "2023-05-15",                      // opcional
  "ai_search_endpoint": "https://<recurso>.search.windows.net",     // opcional
  "ai_search": "<SEARCH_API_KEY>",                                  // opcional
  "ai_search_default_index": "video-index",                          // opcional
  "ai_search_semantic_config": "my-semantic-config"                  // opcional
}
```

Notas:
- `agent_call` (provider `azure-openai`) usa `aoai_*` (endpoint, api_key, api_version, chat_deployment).

## Perfiles de Agente y RAG ü§ñüîç

‚ö†Ô∏è **Estado**: El nodo `agent_call` y sus capacidades est√°n en **desarrollo activo**. La API puede cambiar en futuras versiones.

El simulador soporta diferentes **perfiles de agente** para distintos casos de uso:

### ‚úÖ Perfiles Estables (Modo Directo sin backend)

Estos perfiles funcionan completamente en el simulador con Azure OpenAI + Azure AI Search:

| Perfil | Estado | Descripci√≥n | Credenciales Requeridas |
|--------|--------|-------------|------------------------|
| `normal` | ‚úÖ Producci√≥n | Chat b√°sico sin herramientas | AOAI: endpoint, api_key, deployment |
| `domain_expert` | ‚úÖ Producci√≥n | Chat con system prompt especializado | AOAI: endpoint, api_key, deployment |
| `rag` | ‚úÖ Producci√≥n | Chat con b√∫squeda en documentos (RAG) | AOAI + AI Search: endpoint, api_key, index |

### üöß Perfiles Experimentales (Requieren Backend)

| Perfil | Estado | Descripci√≥n | Por qu√© requiere backend |
|--------|--------|-------------|--------------------------|
| `coordinator` | üöß Beta | Orquestaci√≥n multi-agente | Tool calling, delegaci√≥n, modos (sequential/group_chat/fanout) |
| `retrieval` | ‚úÖ Producci√≥n | Solo recuperaci√≥n sin generaci√≥n | L√≥gica especial de filtrado y ranking |

### Configuraci√≥n de `agent_call`

**Propiedades principales**:

```javascript
{
  "type": "agent_call",
  "agent_profile": "rag",           // normal | domain_expert | rag | coordinator | retrieval
  "message": "{{input}}",            // Pregunta del usuario (usa plantillas)
  "system_prompt": "...",            // Instrucciones/rol del sistema
  "thread_var": "agent_thread_id",  // Variable para mantener conversaci√≥n
  "stream": true,                    // true=SSE streaming | false=sincr√≥nico
  "save_as": "agent_response",      // Variable destino de la respuesta
  
  // Configuraci√≥n de b√∫squeda (para rag/retrieval)
  "search": {
    "index": "video-index",          // √çndice de Azure AI Search
    "top_k": 3,                       // N√∫mero de documentos a recuperar
    "mode": "hybrid",                 // hybrid | semantic | keyword
    "semanticConfiguration": "..."   // Opcional
  },
  
  // Configuraci√≥n de coordinator (experimental)
  "participants": ["retrieval", "rag", "domain_expert"],  // Sub-agentes
  "mode": "sequential",              // sequential | group_chat | fanout
  
  // Configuraci√≥n de modelo
  "model": {
    "provider": "azure-openai",      // Para modo directo
    "deployment": "gpt-4",
    "temperature": 0.2,
    "max_tokens": 800
  },
  
  "next": "show_response"
}

### Usar RAG en el Simulador

**RAG (Retrieval-Augmented Generation)** permite que el agente busque en documentos antes de generar la respuesta.

**Ejemplo de flujo completo**:

1. **Configura el perfil** con credenciales de Azure AI Search:
```json
{
  "name": "mi-perfil-rag",
  "aoai_endpoint": "https://mi-openai.openai.azure.com",
  "aoai_api_key": "...",
  "aoai_chat_deployment": "gpt-4",
  "ai_search_endpoint": "https://mi-search.search.windows.net",
  "ai_search": "...",
  "ai_search_default_index": "video-index"
}
```

2. **Crea un nodo `agent_call`** con perfil RAG:
```json
{
  "type": "agent_call",
  "agent_profile": "rag",
  "message": "{{input}}",
  "system_prompt": "Eres un asistente que responde usando documentos. Cita las fuentes con [N].",
  "search": {
    "index": "video-index",
    "top_k": 5
  },
  "stream": true,
  "model": {
    "provider": "azure-openai",
    "temperature": 0.2
  },
  "next": "end"
}
```

3. **El simulador autom√°ticamente**:
   - ‚úÖ Consulta Azure AI Search con la pregunta del usuario
   - ‚úÖ Recupera los documentos m√°s relevantes (top_k)
   - ‚úÖ Construye el contexto RAG con los resultados
   - ‚úÖ Env√≠a todo a Azure OpenAI para generar la respuesta contextualizada

**Flujo de ejecuci√≥n RAG**:

```
Usuario: "¬øQu√© dice el video sobre Python?"
   ‚Üì
[Azure AI Search] Busca en √≠ndice "video-index"
   ‚Üì
[Resultados] 5 documentos encontrados:
   [1] video_001.mp4: "Tutorial de Python b√°sico..."
   [2] video_002.mp4: "Python para ciencia de datos..."
   ...
   ‚Üì
[Contexto RAG] Se construye con los documentos
   ‚Üì
[Azure OpenAI] Genera respuesta usando el contexto
   ‚Üì
Respuesta: "Seg√∫n los documentos encontrados [1][2], 
            Python es un lenguaje de programaci√≥n..."
```

### Herramientas de Prueba y Diagn√≥stico

**Para probar RAG y agentes**:

- üß™ **`test_rag.html`**: Interfaz visual standalone para probar b√∫squedas en Azure AI Search y RAG completo
  - Prueba solo b√∫squeda para ver qu√© documentos encuentra
  - Prueba RAG completo (b√∫squeda + generaci√≥n de respuesta)
  - Visualiza resultados, contexto y respuesta del agente

- üîç **`debug_profiles.html`**: Diagn√≥stico de credenciales y perfiles
  - Inspecciona contenido de localStorage
  - Verifica perfiles disponibles y perfil activo
  - Prueba resoluci√≥n de credenciales paso a paso

- üìñ **`docs/simulador_rag.md`**: Documentaci√≥n completa del flujo RAG
  - C√≥mo funciona RAG internamente
  - Comparaci√≥n: modo directo vs backend
  - Troubleshooting y soluci√≥n de problemas

- üìù **`docs/guia_rapida_rag.md`**: Gu√≠a paso a paso para comenzar con RAG
  - Configuraci√≥n de credenciales
  - Ejecuci√≥n del flujo demo
  - Verificaci√≥n de logs

- üéØ **`docs/demo_agent_rag.json`**: Flujo de ejemplo completo y funcional
  - Importar directamente desde el simulador
  - Ver configuraci√≥n completa de RAG
  - Ejemplo de buenas pr√°cticas

### Logs de Diagn√≥stico

En la consola del navegador (F12) ver√°s el flujo completo de ejecuci√≥n:

**Para perfiles en modo directo** (`normal`, `domain_expert`, `rag`):
```
[Simulador] Usando Azure OpenAI directo (perfil: rag)
[AOAI] Perfil activo: mi-perfil-rag
[AOAI] Credenciales finales: endpoint: https://...
[RAG] Perfil RAG detectado, iniciando b√∫squeda en Azure AI Search...
[RAG] Consultando: https://....search.windows.net/indexes/video-index/docs/search?...
[RAG] Encontrados 5 resultados
[RAG] Contexto construido: [1] video_001.mp4: ...
```

**Para perfiles que requieren backend** (`coordinator`, `retrieval`):
```
[Simulador] ‚ö†Ô∏è Perfil coordinator NO soportado en modo directo (requiere backend)
‚ö†Ô∏è El perfil "coordinator" requiere el backend para funcionar correctamente.

Este perfil utiliza capacidades avanzadas (orquestaci√≥n multi-agente, tools personalizados)
que no est√°n disponibles en el modo directo de Azure OpenAI.

‚úÖ Para probar este perfil, aseg√∫rate de que el backend est√© ejecut√°ndose en: http://localhost:5000
```

### Comparaci√≥n: Modo Directo vs Backend

| Caracter√≠stica | Modo Directo (Simulador) | Backend |
|----------------|--------------------------|---------|
| **Perfiles soportados** | `normal`, `domain_expert`, `rag` | Todos |
| **Latencia** | ‚úÖ Baja (sin hop adicional) | ‚ö†Ô∏è Media (pasa por backend) |
| **B√∫squeda (RAG)** | ‚úÖ Simple (searchMode: 'any') | ‚úÖ Avanzada (ranking, filtros sem√°nticos) |
| **Tool calling** | ‚ùå No | ‚úÖ S√≠ |
| **Multi-agente** | ‚ùå No | ‚úÖ S√≠ (`coordinator`) |
| **Cach√©** | ‚ùå No | ‚úÖ S√≠ (opcional) |
| **Logs/Telemetr√≠a** | ‚ö†Ô∏è Solo consola navegador | ‚úÖ Azure Monitor, m√©tricas |
| **CORS** | ‚ö†Ô∏è Requiere configuraci√≥n | ‚úÖ Gestionado por backend |
| **Deployment** | ‚úÖ Ninguno (solo navegador) | ‚ö†Ô∏è Requiere infraestructura |

**Recomendaci√≥n**: 
- **Desarrollo/Prototipado**: Usa modo directo para perfiles simples y RAG
- **Producci√≥n**: Usa backend para funcionalidad completa, observabilidad y seguridad

### Mejores Pr√°cticas para `agent_call` üìå

**Variables y plantillas**:
- ‚úÖ Usa `{{ input }}` para inyectar la pregunta del usuario en `message`
- ‚úÖ Evita saltos de l√≠nea dentro de `{{ }}` (escribe en una sola l√≠nea)
- ‚úÖ El backend persiste autom√°ticamente `request.input` en variables `input` y `last_user_input`
- ‚ùå No dejes `message` vac√≠o (el backend omitir√° la llamada)

**System prompts**:
- ‚úÖ S√© espec√≠fico sobre el formato de respuesta esperado
- ‚úÖ Para RAG: instruye al modelo a citar fuentes con `[N]`
- ‚úÖ Define el tono y rol claramente (ej: "Eres un experto en...")
- ‚ö†Ô∏è System prompts muy largos consumen tokens

**Conversaciones (threads)**:
- ‚úÖ Usa `thread_var` para mantener contexto entre turnos
- ‚úÖ Guarda el valor en una variable persistente (ej: `"thread_var": "agent_thread_id"`)
- ‚ö†Ô∏è Los threads tienen l√≠mite de tokens acumulados

**Streaming**:
- ‚úÖ `stream: true` - Mejor UX (respuesta incremental)
- ‚úÖ `stream: false` - √ötil cuando necesitas procesar la respuesta completa con `assign_var`
- ‚ö†Ô∏è Streaming requiere que el nodo siguiente sea `end` o no dependa de la respuesta

**RAG y b√∫squeda**:
- ‚úÖ Usa `top_k` entre 3-5 para balance entre contexto y tokens
- ‚úÖ `searchMode: "hybrid"` combina b√∫squeda sem√°ntica y por palabras clave
- ‚ö†Ô∏è √çndices grandes pueden requerir filtros para mejorar precisi√≥n
- ‚ö†Ô∏è CORS debe estar habilitado en Azure AI Search para modo directo

**Manejo de errores**:
- ‚úÖ Configura `mock_mode: "fallback"` durante desarrollo
- ‚úÖ Usa nodos `condition` para validar `agent_response` antes de usarlo
- ‚ö†Ô∏è En producci√≥n, valida que las credenciales est√©n configuradas

**Perfiles experimentales** (`coordinator`):
- ‚ö†Ô∏è API inestable, puede cambiar sin aviso
- ‚ö†Ô∏è Solo para experimentaci√≥n, no usar en producci√≥n
- ‚úÖ Los modos `sequential`, `group_chat`, `fanout` tienen comportamientos diferentes
- ‚ö†Ô∏è Costes de tokens se multiplican (varios agentes ejecut√°ndose)

### Troubleshooting R√°pido de Agentes üîß

<details>
<summary><strong>"Faltan credenciales Azure OpenAI"</strong></summary>

**Causa**: El perfil activo no tiene credenciales completas.

**Soluci√≥n**:
1. Abre el Gestor de Perfiles (bot√≥n en cabecera)
2. Verifica que el perfil activo tenga:
   - `aoai_endpoint`
   - `aoai_api_key`
   - `aoai_chat_deployment`
3. Usa el bot√≥n **"Probar AOAI"** para validar
4. Si falla, revisa las credenciales en Azure Portal

</details>

<details>
<summary><strong>"Faltan credenciales de Azure AI Search" (RAG)</strong></summary>

**Causa**: El perfil activo no tiene credenciales de AI Search.

**Soluci√≥n**:
1. Abre el Gestor de Perfiles
2. Agrega:
   - `ai_search_endpoint`
   - `ai_search` (API key)
   - `ai_search_default_index`
3. Usa el bot√≥n **"Probar SEARCH"** para validar
4. Verifica que el chip de estado muestre "SEARCH OK"

</details>

<details>
<summary><strong>"HTTP 404" al buscar en AI Search</strong></summary>

**Causa**: El √≠ndice no existe o el nombre est√° mal escrito.

**Soluci√≥n**:
1. Ve a Azure Portal ‚Üí AI Search ‚Üí Indexes
2. Verifica que el √≠ndice existe
3. Copia el nombre exacto al perfil
4. Prueba de nuevo con `test_rag.html`

</details>

<details>
<summary><strong>"CORS error" al consultar servicios</strong></summary>

**Causa**: Azure AI Search o Azure OpenAI bloquean peticiones desde tu origen.

**Soluci√≥n**:
1. **Azure AI Search**: Portal ‚Üí CORS ‚Üí Agregar `http://localhost:*` o tu dominio
2. **Azure OpenAI**: CORS est√° habilitado por defecto
3. **Alternativa**: Usa el backend que gestiona CORS por ti

</details>

<details>
<summary><strong>"Perfil coordinator no soportado"</strong></summary>

**Causa**: Los perfiles `coordinator` y `retrieval` requieren backend.

**Soluci√≥n**:
- Usa perfiles `normal`, `domain_expert` o `rag` en modo directo
- O ejecuta el backend para usar perfiles avanzados
- El simulador muestra mensaje explicativo autom√°ticamente

</details>

<details>
<summary><strong>La respuesta no usa los documentos (RAG)</strong></summary>

**Causa**: No se encontraron documentos relevantes o la b√∫squeda fall√≥.

**Soluci√≥n**:
1. Abre consola del navegador (F12)
2. Busca logs `[RAG]`
3. Verifica que `Encontrados N resultados` sea > 0
4. Si N = 0:
   - Reformula la pregunta con t√©rminos m√°s espec√≠ficos
   - Aumenta `top_k` (ej: 5 ‚Üí 10)
   - Verifica que el √≠ndice tenga documentos
5. Usa `test_rag.html` para probar solo la b√∫squeda

</details>

<details>
<summary><strong>El agente responde muy lento</strong></summary>

**Causa**: Modelo grande, contexto extenso o b√∫squeda lenta.

**Soluci√≥n**:
- Reduce `top_k` en b√∫squeda RAG (ej: 5 ‚Üí 3)
- Usa modelo m√°s r√°pido (ej: `gpt-4o-mini` en lugar de `gpt-4`)
- Reduce `max_tokens` si no necesitas respuestas largas
- Acorta el `system_prompt`
- Verifica latencia de red (Azure region)

</details>

---

- Campos de embeddings y Azure AI Search quedan disponibles para nodos o funciones futuras (p. ej., RAG) y para mockear integraciones.

## Contribuciones
¬°Se agradecen issues y PRs! Al contribuir, aceptas que tus aportes se licencian bajo los mismos t√©rminos indicados en la licencia del proyecto para su inclusi√≥n.

 

## Aviso sobre el backend
- El backend que interpreta y ejecuta el JSON NO est√° incluido en este repositorio.
- Ese componente es propietario y no open source.
- Este editor genera el JSON de flujo y ayuda a probarlo de forma limitada con el simulador.

## Estructura r√°pida
- `index.html`: app principal.
- `components/`: paneles HTML para cada tipo de nodo.
- `js/`: m√≥dulos del editor y simulador (factory, renderers, UI, serializer, etc.).
- `js/renderers/`: renderers de propiedades por nodo.
- `css/style.css`: estilos.
- `docs/nodo.md`: documentaci√≥n de nodos.

## Roadmap y Estado Actual üó∫Ô∏è

### ‚úÖ Completado (Producci√≥n)

- **Editor visual** completo con drag & drop, canvas, prop panels
- **25+ tipos de nodos** documentados y funcionales
- **Simulador** con soporte para la mayor√≠a de nodos
- **Sistema de perfiles** para gesti√≥n de credenciales (localStorage)
- **Expresiones y funciones** (40+ funciones matem√°ticas, string, lista, l√≥gicas)
- **Internacionalizaci√≥n (i18n)** con soporte multi-idioma
- **Agentes b√°sicos** (`normal`, `domain_expert`) en modo directo
- **RAG completo** con Azure AI Search + Azure OpenAI
- **Streaming SSE** para respuestas incrementales
- **Mock modes** (off/fallback/always) para desarrollo sin servicios
- **Herramientas de debug** (test_rag.html, debug_profiles.html)

### üöß En Desarrollo (Beta/Experimental)

- **Perfiles de agente avanzados**:
  - ‚ö†Ô∏è `coordinator` (orquestaci√≥n multi-agente: sequential/group_chat/fanout)
  - ‚ö†Ô∏è Tool calling personalizado
  - ‚ö†Ô∏è Mejoras en ranking y filtrado sem√°ntico (RAG avanzado)

- **UI del editor**:
  - Mejoras en el panel de `agent_call`
  - Validaciones en tiempo real de credenciales
  - Preview de b√∫squeda RAG en el editor

### üìã Pendiente (Futuro)

**Validaciones y testing**:
- Validaciones avanzadas por nodo (tipado de variables, linting de rutas)
- Pruebas autom√°ticas del flujo (simulaci√≥n headless, snapshots I/O)
- Cobertura de caminos y detecci√≥n de nodos inalcanzables

**Colaboraci√≥n**:
- Control de versiones de flujos (Git-like)
- Comentarios y anotaciones en nodos
- Modo multiusuario

**Biblioteca y reutilizaci√≥n**:
- Plantillas/snippets reutilizables por dominio
- Biblioteca de flujos comunitarios
- Composici√≥n de sub-flujos (importar flujos como nodos)

**Extensibilidad**:
- Plugins/extensiones para renderers personalizados
- Validadores espec√≠ficos por tipo de nodo
- Conectores a distintos backends

**Contenido e i18n**:
- Gesti√≥n de cat√°logos de texto
- Sistema de traducci√≥n integrado
- Revisi√≥n y aprobaci√≥n de cambios

**Accesibilidad y UX**:
- Atajos de teclado completos
- Modo compacto del canvas
- Ayudas contextuales y tooltips
- B√∫squeda de nodos en el canvas

**Agentes y LLM** (largo plazo):
- MCP (Model Context Protocol): actuar como proveedor/consumidor
- A2A (Agent-to-Agent): coordinaci√≥n y negociaci√≥n entre agentes
- Funci√≥n calling estructurado con validaci√≥n de esquemas
- Observabilidad LLM: trazas, contadores de tokens, costes por sesi√≥n
- Evaluaci√≥n de calidad de respuestas (RAG metrics)

## Visi√≥n y futuras ideas (Archivo)
- Colaboraci√≥n y control de versiones de flujos (multiusuario, cambios comentados).
- Validaciones avanzadas: tipado de variables, linting de rutas, cobertura de caminos.
- Biblioteca de plantillas/snippets reutilizables por dominio.
- Plugins/extensiones: renderers personalizados y validadores espec√≠ficos.
- Pruebas autom√°ticas del flujo (simulaci√≥n headless, snapshots de I/O).
- Integraciones: import/export desde otras herramientas y conectores a distintos backends.
- Gesti√≥n de contenido e i18n (cat√°logos, traducciones, revisi√≥n).
- Accesibilidad y UX: atajos de teclado, modo compacto, ayudas contextuales.
- Agentes: orquestaci√≥n de agentes con herramientas/acciones, memoria y objetivos dentro del grafo de nodos.
- MCP (Model Context Protocol): actuar como proveedor y/o consumidor para integrar herramientas y contextos est√°ndar.
- A2A (Agent-to-Agent): coordinaci√≥n entre agentes, negociaci√≥n de pasos y transferencia de estado.
- Conexiones por LLM: function/tool calling, validaci√≥n de esquemas/JSON, structured outputs y manejo de errores.
- RAG: conectores a fuentes de conocimiento y evaluaciones de calidad de respuesta.
- Observabilidad LLM: trazas, contadores de tokens y costes por sesi√≥n.

## Cr√©ditos
¬© Elbrinner da Silva Fernandes ‚Äî Autores de BRI-FLOW.

## Licencia
Este proyecto se distribuye bajo Business Source License 1.1 (BUSL-1.1). Consulta el archivo `LICENSE.md` para m√°s detalles.
